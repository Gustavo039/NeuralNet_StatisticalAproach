[
  {
    "objectID": "GD.html",
    "href": "GD.html",
    "title": "1  Regressão Linear e Gradiente Descendente",
    "section": "",
    "text": "2 Regressão Linear\nA regressão linear simples é um método estatístico utilizado para modelar a relação entre duas variáveis: uma variável dependente (ou resposta), que desejamos prever, e uma variável independente (ou explicativa), que usamos para fazer essa previsão. O objetivo da regressão linear é encontrar uma função linear que melhor descreva essa relação.\nPor exemplo: podemos utilizar o número de banheiros e quartos de uma casa para predizer seu valor, o número de gols de um atacante utilizando seu histórico dos últimos anos e sua idade ou ainda em um cenário atual, muitas startups que desenvolvem tecnologias de inteligência artificial estão usando regressão linear para prever receitas futuras com base em métricas como usuários ativos, engajamento em plataformas digitais e número de clientes corporativos.\nDentro de uma visão matemática e estatística, um modelo de regressão linear possui uma das estruturas mais simples, dado por:\n\\[Y = \\beta_0 +\\beta_1x_1 + \\epsilon\\]\nonde\nA essência da regressão linear simples está na tentativa de ajustar uma linha reta aos dados que minimiza a diferença entre os valores observados de \\(Y\\) e os valores preditos pela linha, utilizando para isso as variáveis explicativas\nO que torno um modelo em um modelo estatístico são\nO cáculo desses coeficientes possui forma fechada, dada por: \\[(X^TX)^{-1}X^TY\\]\nPela seguinte demonstração\nSeja \\(X\\) a matriz de planejamento. Para um conjunto de dados com \\(p\\) variáveis explicativas e \\(n\\) observações, temos um matriz de planejamento de dimensão \\(n \\ \\times \\ p\\)\nPara se estimar os parametros de uma regressão linear o pensamento mais ismples é: qual o valor dos paramaetros que me retorna o menor erro?\nOu seja, para quais valores dos coeficientes \\(\\beta_0,\\beta_1, ..., \\beta_p\\) temos o menor erro.\nO “menor erro” pode ser estruturada em forma matematica:\n\\[Erro = E_i= Y_i-\\hat Y_i\\] \\[Soma Erro Abs = \\sum E_i^2\\]\nPor sua vez, essa função pode ser chamada de função de custo. Dentro no universo de estatística, aprednizado de máquina e redes neurais diversas função de custos são definidas e utilizadas, satisfzanedo um nicho e onjetivo especifio\nA soma quadratica dos erros é uma das funções mais simples e mais utilizada no contexto de regressão linear\nPara sua minização, temos a seguinte estrutura\nA resposta principal está na formulação em forma fechada da solução, dada por:\n\\[\\beta = (X^TX)^{-1}X^TY\\]\nonde\nA primeira parte da fórmula envolve a inversão da matriz \\((X^TX)\\). Embora a inversão de uma matriz seja possível em teoria, em termos computacionais ela pode ser extremamente custosa. O processo de inversão tem um custo computacional que aumenta exponencialmente com o tamanho da matriz, especialmente à medida que o número de variáveis explicativas (ou colunas de X) aumenta.\nO custo de inverter uma matriz \\(n \\times n\\) é aproximadamente \\(O(N^3)\\) o que significa que, para dados com muitas variáveis, o tempo de execução cresce de maneira cúbica.\nAlém disso, se a matriz \\(X^TX\\) for mal-condicionada (ou seja, quando algumas variáveis são altamente correlacionadas entre si), o processo de inversão pode se tornar instável, resultando em erros numéricos.\nDevido ao elevado custo de calcular diretamente a inversa dE \\(X^TX\\) métodos iterativos, como os baseados em gradiente, são frequentemente preferidos em cenários com grandes conjuntos de dados ou alta dimensionalidade. Esses métodos não exigem a inversão direta da matriz e podem fornecer aproximações suficientemente boas para os coeficientes \\(\\beta\\) com um custo computacional muito menor.\nO gradiente é um conceito central em otimização. Ele representa a direção e a intensidade de variação de uma função com respeito a cada um de seus parâmetros. Em termos mais intuitivos, o gradiente aponta “em que direção” e “o quão rapidamente” o valor da função de custo aumenta ou diminui em relação aos parâmetros.\nPara uma função de custo \\(J(\\theta)\\) onde \\(\\theta\\) representa o vetor de parâmetros, o gradinete de \\(\\nabla J(\\theta)\\) é o vetor de derivadas parciais:\n\\(\\nabla J(\\theta) = (\\frac{\\partial J}{\\partial\\theta_1},\\frac{\\partial J}{\\partial\\theta_2},...,\\frac{\\partial J}{\\partial\\theta_n})\\)\nCada componente desse vetor indica como uma pequena alteração em um parâmetro específico impacta \\(\\theta_i\\) o valor da função de custo. No contexto de minimização, o gradiente fornece a direção em que a função de custo aumenta mais rapidamente. Portanto, para minimizar \\(J(\\theta)\\) ajustamos os parâmetros no sentido oposto ao gradiente — daí o nome “gradiente descendente”.\nDentre o contexto de regressão linear, um conjunto de variáveis pode ser utilizada para predizer o valor de uma outra variável. O processo de escolha de um conjunto de variáveis explicativas que melhor predizem a variável resposta é chamado de modelagem.\nA diferença entre o valor predito e o valor verdadeiro da variável de estudo é chamado de resíduo.\nUma das formas de estimação de um modelo linear é minimizando o o erro total do modelo, ou seja, encontrando o modelo que minimza o valor do resíduo.\nDe maneira detalhada, deseja-se estimar o modelo que minimiza a soma dos resíduos ao quadrado\n\\[SRQ = \\sum^n_{i=0} (y_i - \\hat y_i)^2\\]\nA SRQ pode ser chamada de uma função de custo.\nA minimização entra na área de otimização matematica em otimização.\nExistem diferentes métodos\nO gradiente em relação em relação aos pesos é dado por:\n\\[D_m = \\frac{\\partial(Funcao de Custo)}{\\partial m } = \\frac{\\partial}{\\partial m}(\\frac{1}{n}\\sum^n_{i=0}(y_i - \\hat y)^2)\\]\n\\[D_m = \\frac{2}{n}(\\sum (y_i- \\hat y_i) \\times \\frac{\\partial}{\\partial m}(y_i-\\hat y_i))\\]\n\\[D_m = \\frac{2}{n}(\\sum (y_i- \\hat y_i) \\times \\frac{\\partial}{\\partial m}(y_i - (mx_i + c)))\\]\n\\[D_m = \\frac{2}{n}(\\sum (y_i- \\hat y_i) \\times(-x_i))\\]\n\\[D_m = -\\frac{2}{n}(\\sum x_i(y_i- \\hat y_i))\\]\nAssim os gradientes sáo dados por\n\\[D_M = -\\frac{1}{n}(\\sum x_i (y - \\hat y_i))\\] e\n\\[D_C = -\\frac{1}{n}(\\sum(y_i - \\hat y_i))\\]\n::: {.content-visible when-format=“html”}\nA regressão logística é utilizada quando o desejamos classficar alguma classe. É um método pertencente a classse dos MLGs e possui certes diferenças para a aplaicação do me´todo de Gradiente Descendente\nA regressão logística é dada pela seguinte função\n$$\n$$\nA principal difernça está na definição da função de custo. Enquanto que na regressão linear a principais funções de custo são a soma dos resíduos ao quadrado ou o erro quadratico médio, para o caso logistico utiliza-se o logaritimo da função que representa a regressão logistica, chamada de Binary Cross-Entropy Loss (Log Loss).\nA Binary Cross-Entropy Loss se deriva do custo de erro, dado por:\n\\[\\text{custo}(h_\\theta(x),y)  = \\begin{cases}\n      -\\log(h_{\\theta}(x)) , & \\text{if } y = 1 \\\\\n      -\\log(1 - h_{\\theta}(x)) , & \\text{if } y = 0\n   \\end{cases}\\]\nOu de maneira unificada\n\\[\\text{custo}(h_{\\theta}(x), y) = -y^{(i)} \\times \\log(h_{\\theta}(x^{(i)})) - (1 - y^{(i)}) \\times \\log(h_{\\theta}(x^{(i)}))\\]\nPara \\(m\\) observações, a métrica pode ser simplificada como a média:\n\\[J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m y^{(i)} \\times \\log(h_{\\theta}(x^{(i)})) - (1 - y^{(i)}) \\times \\log(h_{\\theta}(x^{(i)}))\\]\nAssim como no caso da regressão linear, o objetivo é minimizar a função \\(J(\\theta)\\)\nDado um total de \\(n\\) variáveis, assumimos um total de \\(n\\) parâmetros para o vetor \\(\\theta\\). Para minimzar \\(J(\\theta)\\), temos que realizar um Gradiente Descendente em cada parametro de \\(\\theta\\), denominado \\(\\theta_j\\). Onde a cada iteração, a seguinte atualização é realizada\n\\[\\theta_j \\leftarrow \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) \\] Na etapa final do algoritmo, precisamos rodar a o gradiente descendente simultaneamente em cada parametro, ou seja, atualizar \\(\\theta_0, \\theta_1, ..., \\theta_n\\) contidos no vetor \\(\\mathbf{\\theta}\\)\nA atualização em \\(\\theta_j\\) é computada a partir de sua derivada\n\\[\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\\]\nE portanto, substituindo na formula da atualização, temos a seguinte regra:\n\\[\\theta_j \\leftarrow \\theta_j - \\alpha \\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\\]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Redes Neurais Artificiais: um bom lugar para um estatístico se deitar",
    "section": "",
    "text": "Prefácio\nRedes Neurais Artificiais: um bom lugar para um estatístico se deitar\nNos últimos anos, a explosão no volume e na variedade de dados disponíveis tem transformado a forma como enfrentamos desafios analíticos. Este cenário dinâmico tem impulsionado avanços significativos em áreas como a Ciência de Dados, Estatística e Inteligência Artificial, com o desenvolvimento de modelos mais flexíveis e robustos, capazes de lidar com a complexidade crescente dos dados modernos. Modelos que possam lidar com cenários onde o número de variáveis supera o de observações, sem sacrificar a simplicidade e interpretabilidade, tornaram-se cada vez mais essenciais.\nDentro desse contexto, as redes neurais artificiais emergem como uma poderosa metodologia. Apesar de ser um conceito introduzido há décadas no campo da Inteligência Artificial, somente nos últimos anos as redes neurais ganharam uma popularidade generalizada, devido ao seu sucesso em diversas aplicações práticas. Contudo, mesmo com sua ampla aplicabilidade, as redes neurais ainda não são amplamente exploradas em cursos de graduação em Estatística. A terminologia frequentemente associada ao aprendizado de máquinas e a complexidade algorítmica envolvida podem representar barreiras significativas para estatísticos em formação.\nEste livro surge como uma resposta a essa lacuna, oferecendo uma introdução acessível e orientada à modelagem de redes neurais sob uma ótica estatística. Com foco em apresentar os conceitos fundamentais de forma clara e direta, este material busca facilitar o aprendizado para aqueles que já possuem uma base sólida em Estatística, mas que encontram dificuldades ao transitar para áreas como o Aprendizado de Máquinas. Além disso, o livro se complementa com rotinas implementadas em R, permitindo uma aplicação prática e concreta dos modelos discutidos.\nEstudos de simulação também serão explorados para avaliar a performance dos estimadores sob diferentes configurações, tais como funções de ativação, número de camadas ocultas (hidden layers), tamanho da amostra e função de perda — um componente crítico no processo de otimização e estimação via backpropagation. A combinação dessas abordagens permitirá uma compreensão mais profunda e adaptada ao público estatístico, trazendo luz às potencialidades e limitações das redes neurais artificiais em cenários reais."
  },
  {
    "objectID": "GD.html#o-gradiente-descendente-como-alternativa-à-ols",
    "href": "GD.html#o-gradiente-descendente-como-alternativa-à-ols",
    "title": "1  Regressão Linear e Gradiente Descendente",
    "section": "4.1 O Gradiente Descendente como Alternativa à OLS",
    "text": "4.1 O Gradiente Descendente como Alternativa à OLS\nO gradiente descendente é uma técnica iterativa de otimização que ajusta os parâmetros na direção oposta ao gradiente, com o objetivo de encontrar o ponto de mínimo da função de custo. A atualização dos parâmetros em cada iteração é feita com a seguinte fórmula:\n\\[\\theta^{(t+1)} = \\theta(t) -\\eta\\nabla J(\\theta^{(t)}) \\] Onde:\n\n\\(\\theta^{(t+1)}\\) é o vetor de parâmetros atualizado.\n\\(\\theta^{(t)}\\) é o vetor de parâmetros na iteração atual.\n\\(\\nabla\\) é a taxa de aprendizado (learning rate), um hiperparâmetro que controla o tamanho dos passos de atualização.\n\\(\\nabla J(\\theta(t))\\) é o gradiente da função de custo calculado com base nos parâmetros da iteração atual."
  },
  {
    "objectID": "neuron.html",
    "href": "neuron.html",
    "title": "2  Redes 1: Neuronio",
    "section": "",
    "text": "Dado as definições iniciais das regressões linear e logistica, assim como do metodo de gradiente descendente, podemos passar para a definiçãop de uma Rede Neural. Para um bom entendimento de como funciona uma rede, destricharemos em 3 etapas:\n\nArquitetura\nTipos\nAplicação\n\nUm neurônio em uma rede neural artificial é uma unidade computacional inspirada no funcionamento de um neurônio biológico. Ele recebe múltiplas entradas (inputs), realiza uma operação matemática para processar esses valores e gera uma saída (output). Essa operação geralmente envolve uma soma ponderada das entradas seguida por uma função de ativação, que transforma o valor resultante antes de enviá-lo à próxima camada da rede.\nO neurônio humano é uma célula especializada no sistema nervoso, composta por dendritos, corpo celular (soma), axônio e terminais do axônio (sinapses). Os dendritos recebem sinais químicos e elétricos de outros neurônios, que se acumulam no corpo celular, onde esses sinais são integrados. Se a soma desses sinais ultrapassar um certo limiar, o neurônio gera um impulso elétrico, conhecido como potencial de ação. Esse impulso viaja pelo axônio até os terminais, onde é convertido novamente em sinal químico. Nessa etapa, neurotransmissores são liberados para se comunicar com outros neurônios através das sinapses, formando uma complexa rede de comunicação e processamento. Cada neurônio humano possui milhares de conexões (sinapses) com outros neurônios, o que permite um processamento de informações altamente paralelo e dinâmico, com adaptações complexas que envolvem neuroplasticidade ao longo do tempo.\nJá um neurônio computacional, usado em redes neurais artificiais, é uma representação simplificada do neurônio humano. Ele possui uma estrutura mais básica, composta por entradas, uma soma ponderada e uma função de ativação. Cada entrada do neurônio computacional tem um peso associado, que representa a importância dessa entrada para o resultado final. O neurônio computacional calcula a soma ponderada das entradas, aplica uma função de ativação para transformar o resultado e então gera uma saída. Diferente do neurônio biológico, que pode transmitir informações de maneira complexa e em várias direções, o neurônio computacional apenas encaminha sua saída para os neurônios da próxima camada da rede.\nBasicamento, podemos representar uma neuronio humano e computacional da seguinte forma\n\nUm conjunto de neurônios humanos interconectados é conhecido como rede de neurônios ou rede neural. No cérebro humano, essas redes formam complexas interconexões chamadas de circuitos neurais, que são responsáveis pelo processamento de informações e pela comunicação entre diferentes partes do sistema nervoso.\nNo contexto computacional um conjunto de neurônios também é chamado de uma rede neural.\n\n3 Estrutura Básica\nUm neurónio é a estrura mais básica de uma rede neural. Ele recebe um valor, processa ele, e retorna outro valor que é passado para o neuronio seguinte.\nEm uma linguagem matemática, seja um neurônio \\(K\\) \\(x_1,x_2, ....,x_m\\) variáveis, \\(m+1\\) entradas (inputs) e um vetor de pesos \\(w_1,w_2, ..., w_m\\).\n\nBias Input\n\n\nO input \\(x_0\\) é definido como o valor constante \\(+1\\). Isso o torna o chamado Bias Input, que é utilizado para ajustar o valor de saida do neurônio independente dos damais valores de entrada. Esse termo permite que o neurônio retorne valores diferentes de 0 mesmo quando todos os valores de entrada são iguais a 0.\n\n\nActual Inputs\n\n\nOs valores de entradas remanescente, vindo das variáveis \\(x_1,x_2, ...x_m\\) são chamadas de entradas verdadeiras (Actual Inputs), tendo seu próprio vetor de peso associado \\(w_{k1}, w_{k2},..., w_{km}\\)\n\n\nSoma Ponderada\n\n\nA soma dos valores de entrada ponderadas pelos pesos é realizada, dada por:\n\n\\[z_k = \\phi(\\sum^m_{j=0}w_{kj}x_j)\\]"
  }
]