[
  {
    "objectID": "GD.html",
    "href": "GD.html",
    "title": "1  Regressão Linear e Gradiente Descendente",
    "section": "",
    "text": "2 Regressão Linear\nA regressão linear simples é um método estatístico utilizado para modelar a relação entre duas variáveis: uma variável dependente (ou resposta), que desejamos prever, e uma variável independente (ou explicativa), que usamos para fazer essa previsão. O objetivo da regressão linear é encontrar uma função linear que melhor descreva essa relação.\nPor exemplo: podemos utilizar o número de banheiros e quartos de uma casa para predizer seu valor, o número de gols de um atacante utilizando seu histórico dos últimos anos e sua idade ou ainda em um cenário atual, muitas startups que desenvolvem tecnologias de inteligência artificial estão usando regressão linear para prever receitas futuras com base em métricas como usuários ativos, engajamento em plataformas digitais e número de clientes corporativos.\nDentro de uma visão matemática e estatística, um modelo de regressão linear possui uma das estruturas mais simples, dado por:\n\\[Y = \\beta_0 +\\beta_1x_1 + \\epsilon\\]\nonde\nA essência da regressão linear simples está na tentativa de ajustar uma linha reta aos dados que minimiza a diferença entre os valores observados de \\(Y\\) e os valores preditos pela linha, utilizando para isso as variáveis explicativas\nO que torno um modelo em um modelo estatístico são\nO cáculo desses coeficientes possui forma fechada, dada por: \\[(X^TX)^{-1}X^TY\\]\nPela seguinte demonstração\nSeja \\(X\\) a matriz de planejamento. Para um conjunto de dados com \\(p\\) variáveis explicativas e \\(n\\) observações, temos um matriz de planejamento de dimensão \\(n \\ \\times \\ p\\)\nPara se estimar os parametros de uma regressão linear o pensamento mais ismples é: qual o valor dos paramaetros que me retorna o menor erro?\nOu seja, para quais valores dos coeficientes \\(\\beta_0,\\beta_1, ..., \\beta_p\\) temos o menor erro.\nO “menor erro” pode ser estruturada em forma matematica:\n\\[Erro = E_i= Y_i-\\hat Y_i\\] \\[Soma Erro Abs = \\sum E_i^2\\]\nPor sua vez, essa função pode ser chamada de função de custo. Dentro no universo de estatística, aprednizado de máquina e redes neurais diversas função de custos são definidas e utilizadas, satisfzanedo um nicho e onjetivo especifio\nA soma quadratica dos erros é uma das funções mais simples e mais utilizada no contexto de regressão linear\nPara sua minização, temos a seguinte estrutura\nA resposta principal está na formulação em forma fechada da solução, dada por:\n\\[\\beta = (X^TX)^{-1}X^TY\\]\nonde\nA primeira parte da fórmula envolve a inversão da matriz \\((X^TX)\\). Embora a inversão de uma matriz seja possível em teoria, em termos computacionais ela pode ser extremamente custosa. O processo de inversão tem um custo computacional que aumenta exponencialmente com o tamanho da matriz, especialmente à medida que o número de variáveis explicativas (ou colunas de X) aumenta.\nO custo de inverter uma matriz \\(n \\times n\\) é aproximadamente \\(O(N^3)\\) o que significa que, para dados com muitas variáveis, o tempo de execução cresce de maneira cúbica.\nAlém disso, se a matriz \\(X^TX\\) for mal-condicionada (ou seja, quando algumas variáveis são altamente correlacionadas entre si), o processo de inversão pode se tornar instável, resultando em erros numéricos.\nDevido ao elevado custo de calcular diretamente a inversa dE \\(X^TX\\) métodos iterativos, como os baseados em gradiente, são frequentemente preferidos em cenários com grandes conjuntos de dados ou alta dimensionalidade. Esses métodos não exigem a inversão direta da matriz e podem fornecer aproximações suficientemente boas para os coeficientes \\(\\beta\\) com um custo computacional muito menor.\nO gradiente é um conceito central em otimização. Ele representa a direção e a intensidade de variação de uma função com respeito a cada um de seus parâmetros. Em termos mais intuitivos, o gradiente aponta “em que direção” e “o quão rapidamente” o valor da função de custo aumenta ou diminui em relação aos parâmetros.\nPara uma função de custo \\(J(\\theta)\\) onde \\(\\theta\\) representa o vetor de parâmetros, o gradinete de \\(\\nabla J(\\theta)\\) é o vetor de derivadas parciais:\n\\(\\nabla J(\\theta) = (\\frac{\\partial J}{\\partial\\theta_1},\\frac{\\partial J}{\\partial\\theta_2},...,\\frac{\\partial J}{\\partial\\theta_n})\\)\nCada componente desse vetor indica como uma pequena alteração em um parâmetro específico impacta \\(\\theta_i\\) o valor da função de custo. No contexto de minimização, o gradiente fornece a direção em que a função de custo aumenta mais rapidamente. Portanto, para minimizar \\(J(\\theta)\\) ajustamos os parâmetros no sentido oposto ao gradiente — daí o nome “gradiente descendente”.\nDentre o contexto de regressão linear, um conjunto de variáveis pode ser utilizada para predizer o valor de uma outra variável. O processo de escolha de um conjunto de variáveis explicativas que melhor predizem a variável resposta é chamado de modelagem.\nA diferença entre o valor predito e o valor verdadeiro da variável de estudo é chamado de resíduo.\nUma das formas de estimação de um modelo linear é minimizando o o erro total do modelo, ou seja, encontrando o modelo que minimza o valor do resíduo.\nDe maneira detalhada, deseja-se estimar o modelo que minimiza a soma dos resíduos ao quadrado\n\\[SRQ = \\sum^n_{i=0} (y_i - \\hat y_i)^2\\]\nA SRQ pode ser chamada de uma função de custo.\nA minimização entra na área de otimização matematica em otimização.\nExistem diferentes métodos\nO gradiente em relação em relação aos pesos é dado por:\n\\[D_m = \\frac{\\partial(Funcao de Custo)}{\\partial m } = \\frac{\\partial}{\\partial m}(\\frac{1}{n}\\sum^n_{i=0}(y_i - \\hat y)^2)\\]\n\\[D_m = \\frac{2}{n}(\\sum (y_i- \\hat y_i) \\times \\frac{\\partial}{\\partial m}(y_i-\\hat y_i))\\]\n\\[D_m = \\frac{2}{n}(\\sum (y_i- \\hat y_i) \\times \\frac{\\partial}{\\partial m}(y_i - (mx_i + c)))\\]\n\\[D_m = \\frac{2}{n}(\\sum (y_i- \\hat y_i) \\times(-x_i))\\]\n\\[D_m = -\\frac{2}{n}(\\sum x_i(y_i- \\hat y_i))\\]\nAssim os gradientes sáo dados por\n\\[D_M = -\\frac{1}{n}(\\sum x_i (y - \\hat y_i))\\] e\n\\[D_C = -\\frac{1}{n}(\\sum(y_i - \\hat y_i))\\]\n::: {.content-visible when-format=“html”}\nA regressão logística é utilizada quando o desejamos classficar alguma classe. É um método pertencente a classse dos MLGs e possui certes diferenças para a aplaicação do me´todo de Gradiente Descendente\nA regressão logística é dada pela seguinte função\n$$\n$$\nA principal difernça está na definição da função de custo. Enquanto que na regressão linear a principais funções de custo são a soma dos resíduos ao quadrado ou o erro quadratico médio, para o caso logistico utiliza-se o logaritimo da função que representa a regressão logistica, chamada de Binary Cross-Entropy Loss (Log Loss).\nA Binary Cross-Entropy Loss se deriva do custo de erro, dado por:\n\\[\\text{custo}(h_\\theta(x),y)  = \\begin{cases}\n      -\\log(h_{\\theta}(x)) , & \\text{if } y = 1 \\\\\n      -\\log(1 - h_{\\theta}(x)) , & \\text{if } y = 0\n   \\end{cases}\\]\nOu de maneira unificada\n\\[\\text{custo}(h_{\\theta}(x), y) = -y^{(i)} \\times \\log(h_{\\theta}(x^{(i)})) - (1 - y^{(i)}) \\times \\log(h_{\\theta}(x^{(i)}))\\]\nPara \\(m\\) observações, a métrica pode ser simplificada como a média:\n\\[J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^m y^{(i)} \\times \\log(h_{\\theta}(x^{(i)})) - (1 - y^{(i)}) \\times \\log(h_{\\theta}(x^{(i)}))\\]\nAssim como no caso da regressão linear, o objetivo é minimizar a função \\(J(\\theta)\\)\nDado um total de \\(n\\) variáveis, assumimos um total de \\(n\\) parâmetros para o vetor \\(\\theta\\). Para minimzar \\(J(\\theta)\\), temos que realizar um Gradiente Descendente em cada parametro de \\(\\theta\\), denominado \\(\\theta_j\\). Onde a cada iteração, a seguinte atualização é realizada\n\\[\\theta_j \\leftarrow \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta) \\] Na etapa final do algoritmo, precisamos rodar a o gradiente descendente simultaneamente em cada parametro, ou seja, atualizar \\(\\theta_0, \\theta_1, ..., \\theta_n\\) contidos no vetor \\(\\mathbf{\\theta}\\)\nA atualização em \\(\\theta_j\\) é computada a partir de sua derivada\n\\[\\frac{\\partial}{\\partial\\theta_j}J(\\theta) = \\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\\]\nE portanto, substituindo na formula da atualização, temos a seguinte regra:\n\\[\\theta_j \\leftarrow \\theta_j - \\alpha \\frac{1}{m}\\sum^m_{i=1}(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j\\]\nAlem das funções de custo ja listadas, outras são definidas para determinados nichos e obejtivos. O seguinte tópico buscou listar as principais."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Redes Neurais Artificiais: um bom lugar para um estatístico se deitar",
    "section": "",
    "text": "Prefácio\nRedes Neurais Artificiais: um bom lugar para um estatístico se deitar\nNos últimos anos, a explosão no volume e na variedade de dados disponíveis tem transformado a forma como enfrentamos desafios analíticos. Este cenário dinâmico tem impulsionado avanços significativos em áreas como a Ciência de Dados, Estatística e Inteligência Artificial, com o desenvolvimento de modelos mais flexíveis e robustos, capazes de lidar com a complexidade crescente dos dados modernos. Modelos que possam lidar com cenários onde o número de variáveis supera o de observações, sem sacrificar a simplicidade e interpretabilidade, tornaram-se cada vez mais essenciais.\nDentro desse contexto, as redes neurais artificiais emergem como uma poderosa metodologia. Apesar de ser um conceito introduzido há décadas no campo da Inteligência Artificial, somente nos últimos anos as redes neurais ganharam uma popularidade generalizada, devido ao seu sucesso em diversas aplicações práticas. Contudo, mesmo com sua ampla aplicabilidade, as redes neurais ainda não são amplamente exploradas em cursos de graduação em Estatística. A terminologia frequentemente associada ao aprendizado de máquinas e a complexidade algorítmica envolvida podem representar barreiras significativas para estatísticos em formação.\nEste livro surge como uma resposta a essa lacuna, oferecendo uma introdução acessível e orientada à modelagem de redes neurais sob uma ótica estatística. Com foco em apresentar os conceitos fundamentais de forma clara e direta, este material busca facilitar o aprendizado para aqueles que já possuem uma base sólida em Estatística, mas que encontram dificuldades ao transitar para áreas como o Aprendizado de Máquinas. Além disso, o livro se complementa com rotinas implementadas em R, permitindo uma aplicação prática e concreta dos modelos discutidos.\nEstudos de simulação também serão explorados para avaliar a performance dos estimadores sob diferentes configurações, tais como funções de ativação, número de camadas ocultas (hidden layers), tamanho da amostra e função de perda — um componente crítico no processo de otimização e estimação via backpropagation. A combinação dessas abordagens permitirá uma compreensão mais profunda e adaptada ao público estatístico, trazendo luz às potencialidades e limitações das redes neurais artificiais em cenários reais."
  },
  {
    "objectID": "GD.html#o-gradiente-descendente-como-alternativa-à-ols",
    "href": "GD.html#o-gradiente-descendente-como-alternativa-à-ols",
    "title": "1  Regressão Linear e Gradiente Descendente",
    "section": "4.1 O Gradiente Descendente como Alternativa à OLS",
    "text": "4.1 O Gradiente Descendente como Alternativa à OLS\nO gradiente descendente é uma técnica iterativa de otimização que ajusta os parâmetros na direção oposta ao gradiente, com o objetivo de encontrar o ponto de mínimo da função de custo. A atualização dos parâmetros em cada iteração é feita com a seguinte fórmula:\n\\[\\theta^{(t+1)} = \\theta(t) -\\eta\\nabla J(\\theta^{(t)}) \\] Onde:\n\n\\(\\theta^{(t+1)}\\) é o vetor de parâmetros atualizado.\n\\(\\theta^{(t)}\\) é o vetor de parâmetros na iteração atual.\n\\(\\nabla\\) é a taxa de aprendizado (learning rate), um hiperparâmetro que controla o tamanho dos passos de atualização.\n\\(\\nabla J(\\theta(t))\\) é o gradiente da função de custo calculado com base nos parâmetros da iteração atual."
  },
  {
    "objectID": "neuron.html",
    "href": "neuron.html",
    "title": "2  Neuronios e Camadas",
    "section": "",
    "text": "3 Estrutura Básica\nUm neurónio é a estrura mais básica de uma rede neural. Ele recebe um valor, processa ele, e retorna outro valor que é passado para o neuronio seguinte.\nEm uma linguagem matemática, seja um neurônio \\(K\\) \\(x_1,x_2, ....,x_m\\) variáveis, \\(m+1\\) entradas (inputs) e um vetor de pesos \\(w_1,w_2, ..., w_m\\).\n\\[z_k = \\phi(\\sum^m_{j=0}w_{kj}x_j) + b\\]\nEm rede neural, o fluxo dos dados percorre os neuronios atraves de determinados caminhos, chamados de Camadas.\nUma camada (layer) pode ser caracterizada como um conjunto de neuronios, onde neuronios de diferentes camadas possuem comunicação, porem neuronios de uma mesma camadas não possuem nenhuma ligação\nUma rede possui 3 camadas distintas: Entrada (Input), Oculta (Hidden) e Saida (Output)\nComo definimos na seção “Estrutura Básica”, um neurônio é definido algebricamente como \\[z_k = \\phi(\\sum^m_{j=0}w_{kj}x_j) + b\\], onde \\(phi\\) é uma função chamada de função de ativação. Ela é responsável por transformar o valor bruto calculado por um neurônio (o somatório ponderado das entradas mais o viés) em uma saída que será transmitida para os neurônios da próxima camada. O principal objetivo dessa transformação é introduzir não-linearidade no modelo, permitindo que ele aprenda padrões complexos nos dados.\nSem uma função de ativação, a rede neural seria equivalente a uma combinação linear das entradas, independentemente de quantas camadas fossem adicionadas. Isso significa que ela só poderia resolver problemas simples e lineares. A introdução de não-linearidade torna possível a resolução de problemas mais desafiadores, como a classificação de dados que não podem ser separados por uma linha ou plano.\nAtualmente, existem diversas funções de ativação já definidas, onde cada uma possui uma nicho específico de utilização. Listamos as mais conhecidas\nVale destacar que uma função de ativação e função de custo são coisas DISTINTAS. Enquanto uma função de ativação é aplicada localmente em cada neurônio, uma função de custo é aplicada apenas na sáida final da rede, ou seja, no momento da predição de valores, tendo o objetivo de calcular o erro global da rede. Essa função é utilizada para a otimização dos pesos e vieses durante o treinamento. Resumidamente, a função de ativação transforma os sinais dentro da rede para capturar padrões, enquanto a função de custo avalia o erro final das previsões para guiar o aprendizado do modelo.\nO objetivo do Backpropagation é calcular as derivadas parciais \\(\\frac{\\partial C}{\\partial w}\\) e \\(\\frac{\\partial C}{\\partial b}\\), onde \\(C\\) é função de custo, \\(w\\) é o peso (weight) e \\(b\\) é o viés (bias). Para o método funcionar, precisamos definir duas suposições\nO GD e BCK fazem um trabalho de turma\nRelembrando, Gradient Descent é um algoritmo usado para minimizar uma função, neste caso, a função de custo \\(C(\\theta)\\), onde \\(\\theta\\) representa a matriz de parâmetros: pesos e vieses\nO desafio mora no calculo do gradiente \\(\\nabla_{\\theta}L(\\theta)\\), que é aí que se utiliza o Backpropagation\nBackpropagation é um algoritmo para calcular os gradientes da função de custo em relação aos pesos e vieses da rede de forma eficiente usando a regra da cadeia. Funciona camada por camada, começando pela camada de saída (final da rede) e retrocedendo em direção à entrada.\nEm conjunto eles, temos a seguinte sequencia"
  },
  {
    "objectID": "GD.html#função-de-custo-exponencial",
    "href": "GD.html#função-de-custo-exponencial",
    "title": "1  Regressão Linear e Gradiente Descendente",
    "section": "10.1 Função de Custo Exponencial",
    "text": "10.1 Função de Custo Exponencial\nUtilizada para o algoritmo AdaBoost de classsificação, onde sua forma de convexidade e crescimento exponencial para valroes negativos a torna sensivel para valores outliers. Dada por\n\\[f(x) = \\frac{1}{2}log(\\frac{p(1|x)}{1-p(1|x)})\\]"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "neuron.html#equações",
    "href": "neuron.html#equações",
    "title": "2  Neuronios e Camadas",
    "section": "6.2 Equações",
    "text": "6.2 Equações\nO método se baseia em 4 equações fundamentais\n\n6.2.1 Equação para o erro na camada de saída\n\\[\\delta^L_j = \\frac{\\partial C}{\\partial a^L_j}\\sigma´(z^L_j)\\]\nO primeiro termo a direta, \\(\\frac{\\partial C}{\\partial a^L_j}\\) mensura o quão rápido a função de custo está se adaptando em relação ao j-ésimo neurônio de saída. Por exemplo, se a função custo não depender muito de um neuronio j em particular, portanto \\(\\delta^L_j\\) será um valor pequeno\nJá o segundo termo a direita, \\(\\sigma´(z^L_j)\\), mensura o quão rápido a função de ativação \\(\\sigma\\) esta mudando em relação a \\(z^L_j\\)\nNa forma matricial a BP1 possui a seguinte forma\n\\[\\sigma^L = \\Delta_aC \\odot \\sigma´ (z^L)\\] Onde, \\(\\Delta_aC\\) é definido como o vetor que sias componentes são as derivadas parciais \\(\\frac{\\partial C}{\\partial a^L_j}\\), para facilitar o entedimento, podemos expressar \\(\\Delta_aC\\) como a taxa de variação de \\(C\\) em relação ao ativações de saída\n\n\n6.2.2 Equação para o erro\nA equação para o erro \\(\\delta^l\\) em relação ao erro uam camada a frente, \\(\\delta^{l+1}\\) é dado por\n\\[\\delta^l = ((w^{l+1})^T\\delta^{l+1})\\odot\\sigma´(z^l)\\]\nOnde \\((w^{l+1})^T\\) é a matriz transposta da matriz de pesos \\(w^{l+1}\\) para a \\(l+1\\)-ésima camada\n\n\n6.2.3 Equação para a taxa de variação do custo em relação aos vieses\n\\[\n\\frac{\\partial C}{\\partial b^l_j} = \\delta^l_j\n\\tag{6.1}\\]\nTemos que o erro \\(\\delta^l_j\\) é exatamente igual a taxa de variação \\(\\frac{\\partial C}{\\partial b^l_j}\\). Isso se mostra como um ponto positivo, dado que já sabemos como calcular \\(\\delta^l_j\\) como visto nas equações BP1 e BP2. Assim podemos escrever a BP3 como\n\\[\\frac{\\partial C}{\\partial b} = \\delta\\]\nOnde \\(\\delta\\) está sendo calculado no mesmo neuronio do viés \\(b\\)\n\n\n6.2.4 Equação para a taxa de variação do custo em relação aos pesos\n\\[\\frac{\\partial C}{\\partial w^l_{jk}} = a^{l-1}_k\\delta^l_j\\]"
  },
  {
    "objectID": "neuron.html#algoritmo",
    "href": "neuron.html#algoritmo",
    "title": "2  Neuronios e Camadas",
    "section": "6.3 Algoritmo",
    "text": "6.3 Algoritmo\nAs funções definidas na seção passada provem uma forma de se calcular o gradiente da função de custo. Essas funções são utilizadas no algortimo do método que possui 5 passos fundamentais\n\nInput x\n\n\nO conjunto dados é introduzido a rede. No pensamento algebrico, o vetor \\(X\\) é introduzido a rede e atribuido como a ativação da camada de entrada\n\n\nFeedforward\n\n\nPara cada camada \\(l = 2,3, ..., L\\) calcula-se os valores retornado pelos neurônios \\(z^l = w^la^{l-1}+b^l\\), onde \\(w^l\\) é a matriz de peso para a camada \\(l\\), \\(a^{l-1}\\) é o valor de ativação da camada anterior, \\(b^l\\) é o vetor de vieses para a camada \\(l\\)\nAlém disso, devemos reforçar que \\(a^l = \\sigma(z^l)\\), onde \\(\\sigma\\) é uma função de ativação\n\n\nErro de Saída\n\n\nO erro na camada de saída é calculado, dado por \\[\\delta^L=\\Delta_aC\\odot\\sigma´(z^L)\\]\n\\(\\Delta_aC\\) é o gradiente da função de custo C em relação ao valor de ativação \\(a^L\\)\n\\(\\sigma´(z^L)\\) é a derivada da função de ligação no valor de ativação \\(z^l\\)\nIsso quantifica o quanto a saída da rede (ativações) se desvia da saída desejada.\n\n\nPropagação do Erro\n\n\nPara cada camada \\(l = L-1,L-2, ...,2\\), o erro para a camada é calculado, dado por \\[\\delta^l = ((w^{l+1})^T\\delta^{l+1})\\odot\\sigma´(z^l)\\]\n\\((w^{l+1})^T\\delta^{l+1}\\) propaga o erro para trás na rede\n\\(\\sigma´(z^l)\\) ajusta o erro baseado na função de ativação\nNessa etapa o erro é propagado para trás, dando origem ao nome do método Backpropagation\n\n\nCalculo dos Gradientes\n\n\nNo último passo do algoritmo, os gradientes em relação aos pesos e vieses são calculados\nPara o peso (weight) temos \\[\\frac{\\partial C}{\\partial w^l_{jk}} = a^{l-1}_k\\delta^l_j\\]\nJá para os vieses (bias) \\[\\frac{\\partial C}{\\partial b^l_{j}} = \\delta^l_j\\]\nOs valores calculados para cada gradiente são utilizados no momento da otimização via gradiente descendente, minimizando a função de custo"
  },
  {
    "objectID": "neuron.html#pesos-e-vieses",
    "href": "neuron.html#pesos-e-vieses",
    "title": "2  Neuronios e Camadas",
    "section": "6.1 Pesos e Vieses",
    "text": "6.1 Pesos e Vieses\nAntes de entrar de fato nas equações e formas do método, devemos fazer definições importantes sobre a nomenclatura de certos parâmetros e suas caracteristicas\nQuando falamos de pesos e vieses, há muita confusão sobre a função e aplicação de cada um, onde muitas pessoas utilizam esses termos como sinônimos, o que fortemente não é verdade.\nA confusão entre pesos e vieses surge frequentemente porque ambos são parâmetros de uma rede neural que são ajustados durante o treinamento e determinam coletivamente o comportamento do modelo. No entanto, eles servem a propósitos e funções distintas.\nOs pesos (weights) são fatores de multiplicação aplicados aos valores em cada neuronio e determinam a força e direção da relação entre os valores de entrada e de saída de um neurônio.\nJá os vieses (bias) são fatores de soma e permitem o deslocamento da função de ativação, auxiliando que o modelo se ajuste melhor aos dados\nDado uma rede com uma função de ativação \\(At\\), temos o seguinte valor de saida de um determinado neurônio\n\\[z = At(w_i* x_i) + b\\] Vemos que o peso \\(w_i\\) multiplica o valor de entrada \\(x_i\\), controlando a influência de \\(x_i\\) no neuronio atual. Já o vies \\(b\\) é somado ao valor retornado pela função de ativação, auxiliando o neuronio a melhor se ajustar aos dados\nAs principais diferenças podem resumidas em uma tabela"
  },
  {
    "objectID": "neuron.html#exemplo",
    "href": "neuron.html#exemplo",
    "title": "2  Neuronios e Camadas",
    "section": "7.1 Exemplo",
    "text": "7.1 Exemplo\nO exemplo a seguir foi desenvolvido para ilustrar o treinamento de uma rede neural utilizando os algoritmos de Gradiente Descendente e Backpropagation.\nO problema abordado é do tipo regressão, com o objetivo de prever um valor numérico. A estrutura da rede foi definida da seguinte maneira: a camada de entrada possui 3 features, a camada oculta contém 2 neurônios, e a camada de saída é composta por 1 neurônio, responsável por gerar a predição final.\nA função de ativação utilizada é a ReLU com a função de custo Erro Quadrático Médio\nPara facilitar os calculos, utilizaremos a seguinte nomenclatura para um neuronio\n\nO funcionamento de um neurônio pode ser dividido em duas etapas principais. A primeira etapa corresponde à soma ponderada dos valores de entrada, calculada como \\(Net = \\sum_{i=1}^Ix_iw_i\\), onde \\(x_i\\) são os valores da entrada e \\(w_i\\) os respectivos pesos, e Net representa o resultado dessa operação\nA segunda etapa consiste na aplicação da função de ativação ao valor retornado por Net, gerando a saída do neurônio. Esse processo é expresso como \\(Out = Fa(Net) + Bias\\), onde \\(Fa\\) é a função de ativação escolhida e o termo Bias ajusta o resultado final\nEssa separação entre as etapas de cálculo da soma ponderada (Net) e a aplicação da função de ativação (Out) é crucial para a aplicação da regra da cadeia durante o cálculo dos gradientes na etapa de backpropagation.\nConceitualmente, a rede possui a seguinte arquitetura\n É importante ressaltar a nomenclatura utilizada, \\(i\\) refere-se a os inputs, \\(h\\) aos neurônios na camada oculta e \\(o\\) ao neurônio na camada de saída. Para os pesos, de forma generalizada um \\(w_{xyz}\\) representa um peso atrelado x-ésimo neuronio de uma camada anterior, ao y-ésimo neurônio z-ésima camada, onde a rede possui um número de camadas indo de 0 (camada de entrada) a L (camada oculta). Por exemplo, um peso \\(w_212\\) representa um peso que liga o segundo neuronio da camada 1 ao primeiro neuronio da camada 2."
  },
  {
    "objectID": "neuron.html#definindo-os-valores",
    "href": "neuron.html#definindo-os-valores",
    "title": "2  Neuronios e Camadas",
    "section": "7.2 Definindo os Valores",
    "text": "7.2 Definindo os Valores\nPara o exemplo,\n\nO valor verdadeiro é 11"
  },
  {
    "objectID": "neuron.html#forward-pass",
    "href": "neuron.html#forward-pass",
    "title": "2  Neuronios e Camadas",
    "section": "7.3 Forward Pass",
    "text": "7.3 Forward Pass\nPara começar, precisamos da predição inicial da rede dado os pesos e vieses aleatórios de inicialização.\n\nCamada Oculta\n\nO primeiro passo é calcular os valores passados para a camada oculta, calculando os valores de Net e Out\nPara \\(h_1\\) temos\n\\[Net_{h_1} = i_1w_{111} + i_2w_{211} + i_3w_{311}\\] \\[Net_{h_1} = 3*0.5 + 9*0.6 + 21*0.4 = 15.5\\] \\[Out_{h_1} = Fa(Net_{h_1}) + Bias_1\\] \\[Out_{h_1} = max(0;15.5) + 0.5 = 16\\]\nRepetindo os mesmos passos para \\(h_2\\)\n\\[Net_{h_2} = i_1w_{121} + i_2w_{221} + i_3w_{321}\\] \\[Net_{h_2} = 3*0.7 + 9*0.5 + 21*0.6 = 19.2\\] \\[Out_{h_2} = Fa(Net_{h_2}) + Bias_1\\] \\[Out_{h_2} = max(0;19.2) + 0.5 = 19.7\\]\nCom valores de \\(h_1\\) e \\(h_2\\) calculados, podemos calcular o valor de \\(o_1\\)\n\\[Net_{o_1} = h_1w_{112} + h_2w_{212}\\] \\[Net_{o_1} = 16 * 0.4 + 19.7 * 0.9 = 24.1\\] \\[Out_{o_1} = Fa(Net_{o_1}) + Bias_2\\] \\[Out_{o_1} = max(0;24.1) + 0.3 = 24.4\\]"
  },
  {
    "objectID": "neuron.html#calculando-o-erro-total",
    "href": "neuron.html#calculando-o-erro-total",
    "title": "2  Neuronios e Camadas",
    "section": "7.4 Calculando o Erro Total",
    "text": "7.4 Calculando o Erro Total\nCom o valor predito pelo modelo, podemos calcular o Erro, lembrando que o valor verdadeiro é 11. Para o erro, a função de custo utilizada é o Erro Quadrático Médio, dado por\n\\[E_{total} = \\sum\\frac{1}{2}(y-\\hat y)^2\\]\n\n\n\n\n\n\nDica\n\n\n\nO \\(\\frac{1}{2}\\) é incluido para que o expoente seja cancelado durante o calculado da derivada.\n\n\nAssim, temos o seguinte erro\n\\[E_{total} = \\frac{1}{2}(11-24.4)^2 = 89.8\\]"
  },
  {
    "objectID": "neuron.html#backward-pass",
    "href": "neuron.html#backward-pass",
    "title": "2  Neuronios e Camadas",
    "section": "7.5 Backward Pass",
    "text": "7.5 Backward Pass\n!. Camada de Saída\n\nCamada Oculta"
  },
  {
    "objectID": "neuron.html#the-backwards-pass",
    "href": "neuron.html#the-backwards-pass",
    "title": "2  Neuronios e Camadas",
    "section": "7.5 The Backwards Pass",
    "text": "7.5 The Backwards Pass\nO objetivo do backpropagation é utilizar o erro calculado na saída da rede para ajustar os valores dos pesos e vieses de maneira eficiente. Esse ajuste é feito iterativamente, com o intuito de minimizar o erro ao longo do processo de treinamento, levando a uma melhoria contínua no desempenho da rede. Em essência, o backpropagation aplica a regra da cadeia para propagar o erro da camada de saída até as camadas iniciais, identificando como cada peso e viés contribui para o erro, e, em seguida, atualizando esses parâmetros para reduzir gradativamente o valor do erro.\nPara a atualização dos valores dos pesos e vieses, utilizamos o seguinte método:\nPara atualizar o valor de um certo peso, devemos calcular sua constribuição para o erro do total da rede. Por exemplo, se estamos trabalhando com o peso \\(w_{112}\\), sua contribuição é dado pela seguinte derivada\n\\[\\frac{\\partial E_{total}}{\\partial w_{112}}\\]\nO cálculo dessa derivada é realizada através da regra da cadeia\n\\[\\frac{\\partial E_{total}}{\\partial w_{112}} =\n\\frac{\\partial E_{total}}{\\partial out_{o_{1}}}\n\\times\n\\frac{\\partial out_{o_{1}}}{\\partial net_{o_{1}}}\n\\times\n\\frac{\\partial net_{o_{1}}}{\\partial w_{112}}\\]\nPara o cálculo dessas derivadas, devemos antes definir claramente cada função.\n\n\\(E_{total}\\)\n\nÉ a função de custo definida para cada rede. No exemplo estudado, a função de custo definida foi o EQM, dada por \\(E_{total} = \\sum\\frac{1}{2}(y-\\hat y)^2 = \\sum\\frac{1}{2}(y-out_{o_1})^2\\)\n\n\\(Out_{o}\\)\n\nA função Out de um determinado neurônio são os valores retornado por Net aplicado na função de ativação, dado por \\(Out_{} = Fa(Net) + Bias\\)\nPara o exemplo, \\(Out_{o_1} = ReLU(Net_{o_1}) + Bias_2\\)\n\n\\(Net_{o}\\)\n\nA função Net é etapa da soma ponderada, onde os valores\nPara o exemplo, \\(Net_{o_1} = Out_{h_1}w_{112} + Out_{h_2}w_{212}\\)\n\n\nCom cada função devidamente definida, podemos calcular as derivadas parciais\n\\[\\frac{\\partial E_{total}}{\\partial out_{o_{1}}}= -(y-out_{o_1})\\]\n\\[\\frac{\\partial out_{o_{1}}}{\\partial net_{o_{1}}} = \\begin{cases}\n0 & \\text{se } net_{o_1} < 0, \\\\\n1 & \\text{se } net_{o_1} > 0.\n\\end{cases}\\]\n\\[\\frac{\\partial net_{o_{1}}}{\\partial w_{112}} = Out_{h_1}\\]\nAssim\n\\[\\frac{\\partial E_{total}}{\\partial w_{112}} = -(y-out_{o_1}) \\times \\begin{cases}\n0 & \\text{se } net_{o_1} < 0, \\\\\n1 & \\text{se } net_{o_1} > 0\n\\end{cases} \\times Out_{h_1}  = -(11 - 24.4) \\times 1 \\times 16 = 214.4\\]\nCom o valor calculado, podemos finalmente atualizar o valor de \\(w_{112}\\). A atualização é dada por\n\\[w_{112}^+ = w_{112} - \\frac{\\partial E_{total}}{\\partial w_{112}} = 0.4 - 214.4 = -214\\]\nVeremos mais pra frente o conceito de tunagem de hiperparametros, onde um deles é a taxa de aprendizado (learning rate), esse parametro é utilizado para ajustar a magnitude do valor atualizado por iteração. Utilizando ele, a atualização é dada por \\[w_{112}^+ = w_{112} - \\alpha \\frac{\\partial E_{total}}{\\partial w_{112}}\\] onde \\(\\alpha\\) é um valor que deve ser tunado (processo semelhante a otimização)"
  }
]